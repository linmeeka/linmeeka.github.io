---
layout:     post
title:      视觉SLAM十四讲 -- 第二讲笔记
subtitle:   SLAM学习笔记
date:       2018-09-06
author:     BY kylin
header-img: img/post-bg-cook.jpg
catalog: true
tags:
    - SLAM
---

##视觉SLAM十四讲 -- 第二讲笔记
### 2.1 引子
slam任务：

* 建图：估计环境
* 定位：估计自身状态

SLAM需要感知外部环境使用，携带传感器。视觉SLAM中使用相机。

* 单目相机：单张图片无法获得深度信息，要动过移动相机形成视差来估计深度。同时，单目相机存在尺度不确定性。
* 双目相机：通过*基线*(两摄像头之间的距离)估计深度。基线越大，可测量的距离越远。深度量程和精度受基线和分辨率限制，计算量消耗大。
* 深度相机：使用ToF、结构光等物理手段，适用于室内。

### 2.2 经典视觉SLAM框架
组成模块：

* 传感器信息读取
* 视觉里程计（visual odometrym/OV/前端）
* 后端优化
* 回环检测
* 建图

目标得到：运动轨迹、地图

#### 2.2.1 视觉里程计
仅使用**相邻图像帧**，估计相机的运动和局部场景。
连续时刻的相机运动构成运动轨迹，各时刻的空间点位置构成地图。
存在问题：误差的累积漂移。
方法：图像特征提取、匹配等

#### 2.2.2 后端优化
处理SLAM过程中的噪声问题。从带噪声的数据中估计整个系统的状态，以及这个状态估计的不确定性。
状态：机器人的轨迹估计和建图估计
方法：吕布、非线性优化

#### 2.2.3 回环检测
判断是否回到了原点（已走过的某点）。若回到原点，则后端调整轨迹和地图，使其符合回环检测。
解决：位置估计随时间漂移。
方案：计算图像数据的相似性。

#### 2.2.4 建图
构建对环境的描述。

* 度量地图：matrix存储
    * 稀疏地图：仅存储路标
    * 稠密地图：使用grid/voxel
* 拓扑地图：graph存储

### SLAM问题的数学表达
#### 表示约束
离散运动时刻：$t=1,…,k$
各时刻的位置估计：$x_1,…,x_k$
可观测的路标点：$y_1,…,y_N$

#### 运动方程
估计运动位置：
$$x_k=f(x_{k-1},u_k,w_k)$$
$u_k$：运动传感器的度数，即输入
$w_k$：噪声

#### 观测方程
描述观测到路标的观测数据：
$$z_{k,j}=h(y_j,x_k,v_{k,j})$$
$v_{k,j}$：观测噪声

#### 参数化
$x_k$使用位姿表示，$z_{k,j}$用距离夹角表示。具体化$f$、$h$。

#### SLAM问题
已知$u$，$z$，在带噪声的情况下，对$x$，$y$进行状态估计。


