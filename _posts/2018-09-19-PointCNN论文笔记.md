---
layout:     post
title:      2018-09-19-PointCNN论文笔记
subtitle:   三维物体识别学习笔记
date:       2018-09-19
author:     BY kylin
header-img: img/post-bg-cook.jpg
catalog: true
tags:
    - 点云
    - 物体识别
    - CNN
---

# PointCNN论文阅读笔记

## 主要思想
这篇论文提出了将卷积层用于三维物体识别的方法，引入一种可学习的矩阵X，对三维点云数据加权、置换。使得卷积能够保留点云的空间位置信息，并且不依赖与点的输入顺序。前层区域内的特征点经卷积操作，得到后层表示点(representative poin)，即前层的高维局部特征表示。此方法可以同时应用在分类和分割任务中，作者介绍了在两类任务中的不同网络架构及细节实现。

## X-conv
> 符号表示
> * 点集P:K个点，每个点D维。(K*D)
> * P中每个点对应一个特征，特征C维。(K*C)
> * X矩阵：K*K

先来看一下对点云数据直接应用卷积存在的问题。
<div align=center>
![figure 1](https://s1.ax2x.com/2018/05/28/7BhmG.png)
![figure 2](https://s1.ax2x.com/2018/05/28/7BvZn.png)
</div>

上图中，图1四个点有序排列在图片中，自然保留着空间结构信息。而对于点云数据，卷积算子的输入是一串点集，存在一下两种情况：
* 四个点分布于不同空间位置，相同次序输入。如图2和图3。对其特征做卷积，得到的结果(f2,f3)相同。因为每个点自有的特征与空间位置无关，此时，丢失了局部各店的结构相关信息。
* 四个点分布于同一空间位置，不同次序输入。如图3和图4。对其特征做卷积，得到的结果(f2,f4)不同。

这说明，**直接卷积会丢失点云的形状信息，并且结果对点的顺序敏感**。究其原因，是图像中点的位置信息隐含在其排列次序中，而点云数据显示的以坐标存储，没有同一的排序规则。将邻域内的点按坐标提特征排序，就可以将无序点云转化为有序点列，而X-conv就是做了这个事情。

文章提出，通过MLP从P学习一个K×K的矩阵，作用于点集P的特征F矩阵，这样，对于输入特征点加权、置换。由于加权操作，同一特征点在不同空间位置拥有不同的权重，解决了上图f2==f3的问题。由于置换操作，点被重新排序，解决了点顺序造成的敏感。即：**理想状态的X变换，能够在考虑点集形状的同时，不依赖于点的输入顺序**。

## 多层卷积
> 符号表示
> * 前层特征：F1(矩阵R1xR1xC1)={$({p_1,i},{f_1,i})$,i=1,2,_,N1}
>   * 其中有N1个D维的点P1i，分别对应N1个C1维的特征f1i。
> * 后层特征：F2(矩阵R2xR2xC2)={$({p_2,i},{f_2,i})$,i=1,2,_,N2}
>   * 其中有N2个D维的点P2i，分别对应N2个C2维特征f2i。
>   * 每一个P2i都是F1中区域点集经X-conv作用得到的表示点。
>   * p：表示点
> * 表示点邻域：N={p1,i}，共K个点。
>   * S={(pi,fi):pi∈N}。N中点Pi和对应fi，即用来计算P的无序点集。
>   * P=(p1,p2,_,pk)'：S中的Pi集合，矩阵KxD。
>   * F=(f1,f2,_,fk)'：S中的fi集合，矩阵KxC1。
> * 卷积核：K(矩阵KxC1+(C_delta)xC2)
> * X：KxK的变换矩阵
> * Fp：表示点P对应的特征


### 如何选取表示点
K作用于F1中的局部区域点集，得到F2中的表示点P，即R2 < R1,而令c2 > c1，则随着卷积层数的加深，特征点的个数逐层减少，而每个特征点的维度加深，即编码了高层信息，表示性提高。

在本文的实现中，对于分类任务，{p2,i}是{p1,i}的随机下采样，对于分割任务，{p2,i}是{p1,i}的最远点采样(farthest point sampling)。*但原文说P不一定是F1中的点，也可以通过投影等方式增强P中信息。*

### 如何计算表示点
确定表示点后，如何通过F1中邻域点S计算得到对应{f2,i}？对于表示点p，需要对它在{p1,i}中的邻域点提取特征，进行卷积操作。

本文选取邻域点S的方法为：对于均匀分布的点云，使用K近邻法。对于非均匀分布的点云，首先使用半径搜索(radius search），再随机采样K个点。需要说明的是，F1中的点可以对应F2的多个表示点。

<div align=center>
![algorithm](https://s1.ax2x.com/2018/05/28/7Bcb2.png)
</div>
算法中，首先将邻域点集P移动到表示点p的坐标系下得到P'，以使得P'表示的是p邻域点集的相对位置关系。之后使用MLP，输入P'，提取空间位置的delta维特征信息F_delta。**注意，这里提取F_delta是逐点应用MLP，与下文计算X矩阵时对整个P'使用MLP不同，这里MLP不太熟悉，要再看一下。**将f_delta和f拼接得到F* ，这样得到了同时含有空间特征信息和原上级特征信息的Kx(C_delta+c1)维特征矩阵F*。

同时，将P'输入MLP，根据点的相对位置信息，训练得到矩阵X。X与F*相乘，对特征矩阵进行加权和置换，得到最终的特征矩阵Fx。最终Fx和卷积核K做传统卷积操作，得到下一层的特征Fp。

文章里说，卷积核K是一个KxC1+(C_delta)xC2的张量，*我的理解是，这里对应的是一维卷积，不再像图像上卷积一样，是一个方形卷积核滑动图像。（反正图像中的卷积最终也被转成矩阵实现，图像中的滑动窗口点也排成了一列）*

## 网络架构
<div align=center>
![figure3](https://s1.ax2x.com/2018/05/28/7BCoz.png)
</div>

本文中，感受野可以定义为K/N，即一个表示点看到了上级的K/N。随着网络加深，每层的表示点越来越少，维度逐渐加深，最终只剩余一个表示点。这个表示点可以看到全局的信息。在这个点后加入全连接层，输出预测概率。网络使用ADAM优化，非线性单元使用ELU，在P‘,Fp和除最后一层的卷基层后加入BN。

为了彻底训练网络，需要更多的表示点连入全连接层。为了保持感受野和网络深度，本文使用了空洞卷积。这样感受野变为KxD/N。测试阶段，多个顶层表示点(对应FC)的输出求均值，再输入softmax层。这个结构用于分类任务。

分割问题中，引入encoder-decoder结构，encoder即分类问题除去FC后的部分，decoder部分则在表示点后再依次加入卷积，输出更少的特征维度和更多的表示点，恢复分辨率。

本文还加入了一些trick，如dropout等防止过拟合方法，训练数据量的选择，对于不同数据集的预处理等。这些细节等日后读到代码再补充。

